{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glassdoor Reviews Tech Market\n",
    "\n",
    "Structure of the Analysis:\n",
    "\n",
    "1. PySpark **environment setup**\n",
    "2. Data source and **Spark data abstraction** (DataFrame) **set up**\n",
    "3. Data set **metadata analysis**:\n",
    "  1. Display **schema and size** of the DataFrame\n",
    "  2. Get one or multiple **random samples** from the data set to better understand what the data is all about\n",
    "4. Remove **NULL values**\n",
    "    1. Shape filtered dataFrame\n",
    "5. Understanding the dataset. Reviews per Year\n",
    "6. **TECH JOB MARKET ANALYSIS**\n",
    "  1. Different types of job\n",
    "     1. The most popular cities among data experts\n",
    "     2. The most popular jobs\n",
    "     3. Jobs with highest overall satisfaction\n",
    "     4. Total number of ML / Data Analyst with reviews\n",
    "     5. Overall satisfaction among DS and Data Analyst compared to the rest\n",
    "  2. Key players\n",
    "      1. Firms with more current employees with reviews\n",
    "      2. Overall satisfaction by firms and current employees\n",
    "        1. Top-performing firms\n",
    "        2. The worst firms\n",
    "      3. Companies with more reviews by current employees in 2019\n",
    "  9. Understanding Amazon\n",
    "      1. Cons\n",
    "      2. Pros\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset was scrapped from the Glassdoor portal by Andre Sionek. It contains data for all countries containing the following terms:\n",
    "\n",
    "* data-scientist\n",
    "* software-engineer\n",
    "* data-analyst\n",
    "* research-scientist\n",
    "* business-analyst\n",
    "* product-manager\n",
    "* project-manager\n",
    "* data-engineer\n",
    "* statistician\n",
    "* dba\n",
    "* database-engineer\n",
    "* machine-learning-engineer\n",
    "\n",
    "Dataset available on Kaggle: https://www.kaggle.com/andresionek/data-jobs-listings-glassdoor?select=glassdoor_reviews.csv\n",
    "\n",
    "LINKT TO THE VIDEO EXPLAINING THE PROJECT:https://youtu.be/bBKK-WoZIvk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PySpark environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "#spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "            .appName(\"DataFrames Glassdoor\")\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data source and Spark data abstraction (DataFrame) setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsDF = spark.read \\\n",
    "                 .option(\"inferSchema\", \"true\") \\\n",
    "                 .option(\"header\", \"true\") \\\n",
    "                 .csv(\"glassdoor_reviews.csv\") \\\n",
    "                 .cache() # optimization to make the processing faster\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data set metadata analysis\n",
    "### A. Display schema and size of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- index: string (nullable = true)\n",
      " |-- reviews.val.cons: string (nullable = true)\n",
      " |-- reviews.val.date: string (nullable = true)\n",
      " |-- reviews.val.featured: string (nullable = true)\n",
      " |-- reviews.val.helpfulCount: string (nullable = true)\n",
      " |-- reviews.val.id: string (nullable = true)\n",
      " |-- reviews.val.pros: string (nullable = true)\n",
      " |-- reviews.val.publishedOn: string (nullable = true)\n",
      " |-- reviews.val.publisher: string (nullable = true)\n",
      " |-- reviews.val.reviewRatings.careerOpportunities: string (nullable = true)\n",
      " |-- reviews.val.reviewRatings.compBenefits: string (nullable = true)\n",
      " |-- reviews.val.reviewRatings.cultureValues: string (nullable = true)\n",
      " |-- reviews.val.reviewRatings.overall: string (nullable = true)\n",
      " |-- reviews.val.reviewRatings.seniorManagement: string (nullable = true)\n",
      " |-- reviews.val.reviewRatings.worklifeBalance: string (nullable = true)\n",
      " |-- reviews.val.reviewerDuration: string (nullable = true)\n",
      " |-- reviews.val.reviewerInformation: string (nullable = true)\n",
      " |-- reviews.val.reviewerJobTitle: string (nullable = true)\n",
      " |-- reviews.val.reviewerLocation: string (nullable = true)\n",
      " |-- reviews.val.reviewerStatus: string (nullable = true)\n",
      " |-- reviews.val.summaryPoints.ceoApproval: string (nullable = true)\n",
      " |-- reviews.val.summaryPoints.outlook: string (nullable = true)\n",
      " |-- reviews.val.summaryPoints.recommend: string (nullable = true)\n",
      " |-- reviews.val.title: string (nullable = true)\n",
      " |-- reviews.val.adviceToManagement: string (nullable = true)\n",
      " |-- reviews.val.companyResponse: string (nullable = true)\n",
      " |-- reviews.val.reviewResponses: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "ReviewsDF has **946168 rows**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "reviewsDF.printSchema()\n",
    "display(Markdown(\"ReviewsDF has **%d rows**.\" % reviewsDF.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting only relevant variables for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions as F\n",
    "reviewsDF = reviewsDF.select(\"id\",\n",
    "                             \"index\",\n",
    "                             (col(\"`reviews.val.cons`\").alias(\"cons\")),\n",
    "                            (col(\"`reviews.val.date`\").alias(\"date\")),\n",
    "                             (col(\"`reviews.val.pros`\").alias(\"pros\")),\n",
    "                             (col(\"`reviews.val.reviewRatings.careerOpportunities`\").alias(\"r_opportunities\")),\n",
    "                             (col(\"`reviews.val.reviewRatings.compBenefits`\").alias(\"r_benefits\")),\n",
    "                             (col(\"`reviews.val.reviewRatings.cultureValues`\").alias(\"r_culture\")),\n",
    "                             (col(\"`reviews.val.reviewRatings.overall`\").alias(\"r_overall\")),\n",
    "                             (col(\"`reviews.val.reviewRatings.seniorManagement`\").alias(\"r_management\")),\n",
    "                             (col(\"`reviews.val.reviewRatings.worklifeBalance`\").alias(\"r_balance\")),\n",
    "                             (col(\"`reviews.val.reviewerDuration`\").alias(\"time_as_employee\")),\n",
    "                             (col(\"`reviews.val.reviewerJobTitle`\").alias(\"job_title\")),\n",
    "                             (col(\"`reviews.val.reviewerStatus`\").alias(\"Current_Employee\")),\n",
    "                             (col(\"`reviews.val.reviewerLocation`\").alias(\"location\")),\n",
    "                             (col(\"`reviews.val.reviewerInformation`\").alias(\"info\")),\n",
    "                             (col(\"`reviews.val.summaryPoints.recommend`\").alias(\"recommend\"))\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Display Schema & Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- index: string (nullable = true)\n",
      " |-- cons: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- pros: string (nullable = true)\n",
      " |-- r_opportunities: string (nullable = true)\n",
      " |-- r_benefits: string (nullable = true)\n",
      " |-- r_culture: string (nullable = true)\n",
      " |-- r_overall: string (nullable = true)\n",
      " |-- r_management: string (nullable = true)\n",
      " |-- r_balance: string (nullable = true)\n",
      " |-- time_as_employee: string (nullable = true)\n",
      " |-- job_title: string (nullable = true)\n",
      " |-- Current_Employee: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- info: string (nullable = true)\n",
      " |-- recommend: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "ReviewsDF has **946168 rows**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviewsDF.printSchema()\n",
    "display(Markdown(\"ReviewsDF has **%d rows**.\" % reviewsDF.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+------------+--------------------+--------------------+----------+--------------+---------------+------------+---------+--------------------+--------------------+----------------+--------------------+--------------------+---------+\n",
      "|                  id|               index|                cons|        date|                pros|     r_opportunities|r_benefits|     r_culture|      r_overall|r_management|r_balance|    time_as_employee|           job_title|Current_Employee|            location|                info|recommend|\n",
      "+--------------------+--------------------+--------------------+------------+--------------------+--------------------+----------+--------------+---------------+------------+---------+--------------------+--------------------+----------------+--------------------+--------------------+---------+\n",
      "|               99762|                null|                null|        null|                null|                null|      null|          null|           null|        null|     null|                null|                null|            null|                null|                null|     null|\n",
      "|              152851|                   2|Binnen bedrijf af...|Nov 29, 2016|Groot internation...|                 4.0|       3.0|           3.0|            4.0|         3.0|      4.0|for more than 5 y...|Marketing Consultant| Former Employee|Naaldwijk (Nether...|Former Employee: ...|        2|\n",
      "|- They worry abou...|                null|                null|        null|                null|                null|      null|          null|           null|        null|     null|                null|                null|            null|                null|                null|     null|\n",
      "|               37027|                   4|salary below aver...| May 1, 2019|good food at lunc...|                 2.0|       1.0|           2.0|            2.0|         1.0|      4.0|for more than 3 y...|            Engineer| Former Employee|Copenhagen (Denmark)|Former Employee: ...|        2|\n",
      "|- Modern technica...|                null|                null|        null|                null|                null|      null|          null|           null|        null|     null|                null|                null|            null|                null|                null|     null|\n",
      "|  Until late in 2018| there was no for...| so product decis...|     product|                   1|                null|      null|          null|           null|        null|     null|                null|                null|            null|                null|                null|     null|\n",
      "|               39554|                   4|Very challenging ...| Sep 1, 2018|Very few to menti...|                 3.0|       4.0|           3.0|            2.0|         4.0|      2.0|                null|                null| Former Employee| Sandyford (Ireland)|Former Employee: ...|        2|\n",
      "|  Excellent training|                null|                null|        null|                null|                null|      null|          null|           null|        null|     null|                null|                null|            null|                null|                null|     null|\n",
      "|Do have a close l...|                null|                null|        null|                null|                null|      null|          null|           null|        null|     null|                null|                null|            null|                null|                null|     null|\n",
      "|               82787|                   1|- lower salaries ...|Sep 18, 2019| - Good environment.|                null|      null|          null|           null|        null|     null|                null|                null|            null|                null|                null|     null|\n",
      "|               30751|                   0|Unclear roadmap f...|Nov 13, 2017|You get to discus...|                null|      null|          null|           null|        null|     null|                null|                null|            null|                null|                null|     null|\n",
      "|Diversit√© des mis...|         2 weeks ago|           Anonymous|         3.0|                 3.0|Former Employee: ...|      null|Paris (France)|Former Employee|         0.0|        0|                   0|                null|            null|                null|     Stage formateur|     null|\n",
      "+--------------------+--------------------+--------------------+------------+--------------------+--------------------+----------+--------------+---------------+------------+---------+--------------------+--------------------+----------------+--------------------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviewsDF.sample(False, 0.00001,33).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We see that there are many rows with only null values. We will create a temporal view to filter for results where id and index are not NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Remove NULL Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crating a teporal view to use Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsDF.createOrReplaceTempView(\"reviews_v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered =spark.sql(\"\"\"SELECT * FROM reviews_v \n",
    "                    WHERE index IS NOT NULL AND date IS NOT NULL AND id IS NOT NULL\n",
    "                    AND r_overall<6\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.createOrReplaceTempView(\"filtered_v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  236639|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT count(*)  FROM filtered_v\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We end up with 236639 rows from the original 946168 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of rows with null values = 74.99\n"
     ]
    }
   ],
   "source": [
    "null_rows= ((946168-236639)/946168)\n",
    "\n",
    "print(\"Percentage of rows with null values =\", (round(null_rows*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Almost 3 out of 4 rows from the dataset were rows with null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Shape filtered dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(236639, 17)\n"
     ]
    }
   ],
   "source": [
    "print((filtered.count(), len(reviewsDF.columns))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Undesrstanding the dataset. Number of reviews per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------------+\n",
      "|Year|number_of_reviews_per_year|\n",
      "+----+--------------------------+\n",
      "|2019|                     86104|\n",
      "|2018|                     35574|\n",
      "|2017|                     19002|\n",
      "|2016|                     10866|\n",
      "|2015|                      6195|\n",
      "|2014|                      3121|\n",
      "|2013|                      1640|\n",
      "|2012|                      1499|\n",
      "|2011|                       283|\n",
      "|2010|                       219|\n",
      "|2009|                       100|\n",
      "|2008|                        78|\n",
      "+----+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT RIGHT(date,4) Year, count(*) number_of_reviews_per_year\n",
    "        FROM filtered_v \n",
    "        WHERE RIGHT(date,4) IN ( \"2020\",\"2019\",\"2018\",\"2017\",\"2016\",\"2015\",\"2014\",\"2013\",\"2012\", \n",
    "                                \"2011\",\"2010\",\"2009\",\"2008\", \"2007\",\"2006\")\n",
    "        GROUP BY Year\n",
    "        ORDER BY number_of_reviews_per_year DESC\n",
    "        \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviews range from 2008 to 2019 and its number has been increasing over the years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.TECH JOB MARKET ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the different types of jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. What are the most popular cities among data experts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------+\n",
      "|location                    |count(location)|\n",
      "+----------------------------+---------------+\n",
      "|Singapore (Singapore)       |9316           |\n",
      "|Shanghai, Shanghai (China)  |5894           |\n",
      "|Bengaluru (India)           |5867           |\n",
      "|Paris (France)              |4939           |\n",
      "|Dublin, Co. Dublin (Ireland)|4732           |\n",
      "+----------------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT location, COUNT(location) \n",
    "        FROM filtered_v\n",
    "        WHERE location IS NOT NULL\n",
    "        GROUP BY location\n",
    "        ORDER BY count(*) DESC\n",
    "        LIMIT 5\"\"\").show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. What are the most popular jobs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----------------------+\n",
      "|job_title               |number_of_professionals|\n",
      "+------------------------+-----------------------+\n",
      "|Software Engineer       |7417                   |\n",
      "|Senior Software Engineer|3234                   |\n",
      "|Intern                  |3008                   |\n",
      "|Manager                 |2851                   |\n",
      "|Project Manager         |2623                   |\n",
      "|Consultant              |2363                   |\n",
      "|Software Developer      |2242                   |\n",
      "|Business Analyst        |2121                   |\n",
      "|Product Manager         |1855                   |\n",
      "|Analyst                 |1524                   |\n",
      "+------------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark.sql(\"\"\"\n",
    "        SELECT job_title, COUNT(job_title) number_of_professionals\n",
    "        FROM filtered_v\n",
    "        WHERE job_title IS NOT NULL AND job_title NOT IN ('Current Employee', 'Former Employee')\n",
    "        GROUP BY job_title\n",
    "        ORDER BY count(*) DESC\n",
    "        LIMIT 10\"\"\").show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Jobs with highest overall satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+--------------------+\n",
      "|job_title                    |Overall_Satisfaction|\n",
      "+-----------------------------+--------------------+\n",
      "|Cloud Support Associate      |5.0                 |\n",
      "|Human Resources Analyst      |4.904458598726115   |\n",
      "|Business Manager             |4.820754716981132   |\n",
      "|Talent Acquisition           |4.772151898734177   |\n",
      "|Software Engineer(Internship)|4.649079754601227   |\n",
      "|Mechanical Engineer          |4.581560283687943   |\n",
      "|Summer Analyst               |4.533519553072626   |\n",
      "|Summer Intern                |4.46078431372549    |\n",
      "|Talent Acquisition Specialist|4.438931297709924   |\n",
      "|Operations Manager           |4.403846153846154   |\n",
      "+-----------------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT job_title, AVG(r_overall) Overall_Satisfaction\n",
    "        FROM filtered_v\n",
    "        WHERE job_title IS NOT NULL AND job_title NOT IN ('Current Employee', 'Former Employee')\n",
    "        GROUP BY job_title\n",
    "        HAVING COUNT(*)> 200\n",
    "        ORDER BY Overall_Satisfaction DESC\n",
    "        LIMIT 10\"\"\").show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. What is the total number of ML / data analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analysts = spark.sql(\"\"\"SELECT *\n",
    "                FROM filtered_v WHERE \n",
    "                                    lower(job_title) LIKE \"%data%\" OR\n",
    "                                    lower(job_title) LIKE \"%lower(ML)%\" OR\n",
    "                                    lower(job_title) LIKE \"%analyst%\" OR\n",
    "                                    lower(job_title) LIKE \"%lower(Machine Learning)%\"\n",
    "                                    \"\"\")\n",
    "data_analysts.createOrReplaceTempView(\"data_analysts_v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|number_data_experts|\n",
      "+-------------------+\n",
      "|              19208|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT count(*) AS number_data_experts\n",
    "                FROM data_analysts_v\n",
    "                                    \"\"\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. What is the average Overall satisfaction among DS/Data Analyst vs the rest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|Overall_Rating|\n",
      "+--------------+\n",
      "|          3.88|\n",
      "+--------------+\n",
      "\n",
      "+--------------------+\n",
      "|Overall_Data_Analyst|\n",
      "+--------------------+\n",
      "|                4.06|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT ROUND(AVG(r_overall),2) AS Overall_Rating\n",
    "                FROM filtered_v\"\"\").show()\n",
    "\n",
    "spark.sql(\"\"\"SELECT ROUND(AVG(r_overall),2) AS Overall_Data_Analyst\n",
    "                FROM data_analysts_v\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scientists and Data Analysts tend to have an ovarall higher satisfaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the firms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Firms with more current employees with reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Firms with more current employees who reviewed on Glassdoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135211"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM filtered_v\n",
    "        WHERE info IS NOT NULL AND Current_Employee==\"Current Employee\"  \"\"\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+-----------------------+\n",
      "|Name_firm|Employees_Reviewed|Percentage_Out_of_total|\n",
      "+---------+------------------+-----------------------+\n",
      "|   Amazon|              4586|                   3.39|\n",
      "|   Oracle|              2128|                   1.57|\n",
      "|   Dell T|              2114|                   1.56|\n",
      "|   Micros|              1224|                   0.91|\n",
      "|   Google|               944|                    0.7|\n",
      "+---------+------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark.sql(\"\"\"\n",
    "        SELECT LEFT(LTRIM(\"Current Employyee: I have been working at \", info),6) Name_firm, COUNT(info) Employees_Reviewed, \n",
    "        ROUND((Count(info)/135211)*100,2) Percentage_Out_of_total\n",
    "        FROM filtered_v\n",
    "        WHERE info IS NOT NULL AND Current_Employee==\"Current Employee\"  \n",
    "        AND LEFT(LTRIM(\"Current Employyee: I have been working at \", info),5) NOT LIKE '%ful%'\n",
    "        GROUP BY Name_firm\n",
    "        ORDER BY count(*) DESC\n",
    "        LIMIT 5\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Companies with most reviews per current employee in year 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------------------------+\n",
      "|Name_firm|N_reviews_in_2019_by_current_employees|\n",
      "+---------+--------------------------------------+\n",
      "| Amazon f|                                  1443|\n",
      "| Dell Tec|                                   857|\n",
      "| Oracle f|                                   692|\n",
      "| Microsof|                                   501|\n",
      "| SAP full|                                   390|\n",
      "| BM full-|                                   381|\n",
      "| Google f|                                   355|\n",
      "| J.P. Mor|                                   323|\n",
      "| PwC full|                                   316|\n",
      "| DXC Tech|                                   307|\n",
      "+---------+--------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT LEFT(LTRIM(\"Current Employyee: I have been working at \", info),8) Name_firm, COUNT(RIGHT(date,4)) N_reviews_in_2019_by_current_employees\n",
    "        FROM filtered_v\n",
    "        WHERE info IS NOT NULL AND Current_Employee==\"Current Employee\" \n",
    "        AND LEFT(LTRIM(\"Current Employyee: I have been working at \", info),5) NOT LIKE '%ful%' AND RIGHT(date,4)='2019'\n",
    "        GROUP BY Name_firm\n",
    "        ORDER BY N_reviews_in_2019_by_current_employees DESC\n",
    "        LIMIT 10\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G. Overall satisfaction by firms and current employees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top-performing firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+---------------+--------+-------------+\n",
      "|Name_firm|Overall_rating|WorkLifeBalance|Benefits|Opportunities|\n",
      "+---------+--------------+---------------+--------+-------------+\n",
      "| Spotify |          4.99|            4.0|     4.5|         4.48|\n",
      "| AirAsia |          4.92|           4.26|    4.89|         4.88|\n",
      "| Zalando |          4.89|            4.9|    4.39|         4.42|\n",
      "| Hays as |          4.88|           3.79|    4.27|         4.71|\n",
      "| Red Hat |          4.83|           4.64|    3.82|         4.41|\n",
      "| Henkel f|          4.81|           4.16|    4.37|         4.73|\n",
      "| Sabre fu|          4.77|           3.35|    4.26|         4.23|\n",
      "| Facebook|          4.74|           3.76|     4.3|         4.13|\n",
      "| Goldman |          4.71|           3.58|    3.93|         4.29|\n",
      "| DataArt |          4.71|           4.58|    4.47|         4.51|\n",
      "+---------+--------------+---------------+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark.sql(\"\"\"\n",
    "        SELECT LEFT(LTRIM(\"Current Employyee: I have been working at \", info),8) Name_firm, \n",
    "        ROUND(AVG(r_overall),2) Overall_rating, ROUND(AVG(r_balance),2) WorkLifeBalance, \n",
    "        ROUND(AVG(r_benefits),2) Benefits,ROUND(AVG(r_opportunities),2) Opportunities\n",
    "        FROM filtered_v\n",
    "        WHERE info IS NOT NULL AND Current_Employee==\"Current Employee\" \n",
    "        AND LEFT(LTRIM(\"Current Employyee: I have been working at \", info),5) NOT LIKE '%ful%'\n",
    "        GROUP BY Name_firm\n",
    "        HAVING COUNT(*)>100\n",
    "        ORDER BY Overall_rating DESC\n",
    "        LIMIT 10\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The worst firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+---------------+--------+-------------+\n",
      "|Name_firm|Overall_rating|WorkLifeBalance|Benefits|Opportunities|\n",
      "+---------+--------------+---------------+--------+-------------+\n",
      "|Sqlink Gr|           2.0|            2.0|     2.0|          1.0|\n",
      "|Mitra Int|          2.52|           2.52|     2.5|         1.52|\n",
      "|Dyson ful|          2.87|           3.08|    2.21|         2.53|\n",
      "|Tiki.vn f|           3.0|            3.0|     2.0|          3.0|\n",
      "|TE Connec|          3.03|           2.78|    2.96|          2.8|\n",
      "|Motorola |          3.21|           3.15|    3.17|         3.41|\n",
      "|Petrofac |          3.36|           3.06|     3.9|         3.07|\n",
      "|Hong Kong|          3.41|           3.24|    2.97|         2.74|\n",
      "|ctronic A|          3.41|           4.06|    3.15|         2.38|\n",
      "|Takeda Ph|          3.42|           3.16|    3.66|         3.06|\n",
      "+---------+--------------+---------------+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT LEFT(LTRIM(\"Current Employyee: I have been working at \", info),9) Name_firm, \n",
    "        ROUND(AVG(r_overall),2) Overall_rating, ROUND(AVG(r_balance),2) WorkLifeBalance, \n",
    "        ROUND(AVG(r_benefits),2) Benefits,ROUND(AVG(r_opportunities),2) Opportunities\n",
    "        FROM filtered_v\n",
    "        WHERE info IS NOT NULL AND Current_Employee==\"Current Employee\" \n",
    "        AND LEFT(LTRIM(\"Current Employyee: I have been working at \", info),5) NOT LIKE '%ful%'\n",
    "        GROUP BY Name_firm\n",
    "        HAVING COUNT(*)>100\n",
    "        ORDER BY Overall_rating\n",
    "        LIMIT 10\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H. Analyzing the most common reviews for data experts at Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import substring_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsDF2=reviewsDF.where(col(\"info\").like(\"%Amazon%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode, regexp_replace, split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cons at Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   cons|count|\n",
      "+-------+-----+\n",
      "|     No|  588|\n",
      "|   time|  558|\n",
      "|   much|  529|\n",
      "|   life|  440|\n",
      "|  often|  413|\n",
      "|balance|  413|\n",
      "|  learn|  399|\n",
      "|    too|  372|\n",
      "|  Cloud|  353|\n",
      "|   take|  349|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df =reviewsDF2.select(explode(split(col(\"cons\"),\" \"))).groupBy(\"col\").count()\n",
    "\n",
    "df.createOrReplaceTempView(\"df\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "            SELECT col cons, count FROM df \n",
    "            WHERE col NOT IN (\"to\",\"the\",\"and\", \"is\",\"to\",\"of\",\"work\", \"a\",\"not\",\"you\",\"The\",\n",
    "            \"in\",\"are\",\"that\", \"have\",\"to\",\"can\",\"for\", \"be\",\"on\", \"great\", \"I\", \"company\", \"it\",\n",
    "            \"as\",\"with\",\"at\", \"very\",\"this\",\"the\",\"no\",\"so\",\"more\", \"your\", \"some\", \" \")\n",
    "            ORDER BY count DESC LIMIT 10\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pros at Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|         pros|count|\n",
      "+-------------+-----+\n",
      "|        Great| 1527|\n",
      "|  environment|  995|\n",
      "|        great|  970|\n",
      "|       people|  965|\n",
      "|             |  964|\n",
      "|      working|  927|\n",
      "|       Amazon|  901|\n",
      "|opportunities|  817|\n",
      "|         fast|  736|\n",
      "|        learn|  734|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df =reviewsDF2.select(explode(split(col(\"pros\"),\" \"))).groupBy(\"col\").count()\n",
    "\n",
    "df.createOrReplaceTempView(\"df\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "            SELECT col pros, count FROM df \n",
    "            WHERE col NOT IN (\"to\",\"the\",\"and\", \"is\",\"to\",\"of\",\"work\", \"a\",\"not\",\"you\",\"The\",\n",
    "            \"in\",\"are\",\"that\", \"have\",\"to\",\"can\",\"for\", \"be\",\"on\",\"I\", \"company\", \"it\",\n",
    "            \"as\",\"with\",\"at\", \"very\",\"this\",\"the\",\"no\", \"much\",\"so\",\"more\", \"your\", \"some\", \" \")\n",
    "            ORDER BY count DESC LIMIT 10\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
